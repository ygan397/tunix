{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fbb885d",
   "metadata": {},
   "source": [
    "## Pre steps to setup the CPU node pool and get k8s credential\n",
    "1. Create a CPU node pool in GKE (update the env var based on your setup)\n",
    "\n",
    "```\n",
    "export PROJECT_ID=cloud-tpu-multipod-dev\n",
    "export CLUSTER_NAME=mlperf-v5p\n",
    "export ZONE=europe-west4\n",
    "export CPU_POOL_NAME=\"tsbao-cpu-pool\"\n",
    "export MACHINE_TYPE=\"n2-standard-8\"\n",
    "export NUM_NODES=1\n",
    "\n",
    "gcloud container node-pools create ${CPU_POOL_NAME}   --cluster=${CLUSTER_NAME}   --zone=${ZONE}   --project=${PROJECT_ID}    --machine-type=${MACHINE_TYPE}   --num-nodes=${NUM_NODES}   --enable-autoscaling --min-nodes=1 --max-nodes=5  --node-labels=\"cloud.google.com/gke-nodepool=${CPU_POOL_NAME}\"\n",
    "```\n",
    "\n",
    "2. Create k8s credential (this will add credential to your local ~/.kube/config)\n",
    "\n",
    "```\n",
    " gcloud container clusters get-credentials ${CLUSTER_NAME} --zone ${ZONE} --project ${PROJECT_ID}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6f5cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcebdf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/scratch/git/rllm')\n",
    "sys.path.insert(0, '/scratch/git/pathways-utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfcc8622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/git/tunix/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "DATASET_CACHE = os.getenv('DATASET_CACHE', '/tmp/dataset_cache')\n",
    "TASKS_TO_PROCESS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbf7fe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 unique Docker images to download\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"R2E-Gym/R2E-Gym-V1\", split=\"train\", cache_dir=DATASET_CACHE, num_proc=32)\n",
    "entries = []\n",
    "unique_images = set()\n",
    "for i, entry in enumerate(dataset):\n",
    "  if \"docker_image\" in entry:\n",
    "    unique_images.add(entry[\"docker_image\"])\n",
    "    entries.append(entry)\n",
    "  if i >= TASKS_TO_PROCESS - 1:\n",
    "    break\n",
    "unique_images = list(unique_images)\n",
    "print(f\"Found {len(unique_images)} unique Docker images to download\")\n",
    "IDS = [f\"task-{i}\" for i in range(len(entries))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0edb57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KUBECONFIG\"] = \"~/.kube/config\"\n",
    "\n",
    "from kubernetes import client, config\n",
    "config.load_kube_config()\n",
    "k8s_client = client.CoreV1Api()\n",
    "# k8s_client.list_namespace(timeout_seconds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2593ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import r2egym\n",
    "\n",
    "# print(r2egym.__file__)\n",
    "# from r2egym.agenthub.runtime.docker import DockerRuntime\n",
    "# from r2egym.agenthub.utils.log import get_logger\n",
    "# from r2egym.agenthub.environment.env import EnvArgs, RepoEnv\n",
    "\n",
    "# env_args = EnvArgs(ds=entries[0])\n",
    "# env = RepoEnv(env_args, backend=\"kubernetes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8a20fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rllm.environments.swe.swe import R2EGYM_COMMAND_FILES\n",
    "\n",
    "# env.add_commands(cmd_files=R2EGYM_COMMAND_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aefcd82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"/tmp/models/DeepSeek-R1-Distill-Qwen-1.5B/DeepSeek-R1-Distill-Qwen-1.5B/\"\n",
    "MODEL_VERSION = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from tunix.rl.agentic.parser.chat_template_parser import parser\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_VERSION)\n",
    "\n",
    "chat_parser = parser.QwenChatTemplateParser(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "297e20ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.sharding import Mesh\n",
    "from tunix.models.qwen2 import params as params_lib\n",
    "from tunix.models.qwen2 import model as model_lib\n",
    "from tunix.sft import utils as sft_utils\n",
    "\n",
    "devices = jax.devices()\n",
    "split = int(len(devices) / 2)\n",
    "rollout_devices = np.array(devices[:split-2]).reshape(split-2, 1)\n",
    "train_devices = np.array(devices[split:]).reshape(split, 1)\n",
    "rollout_mesh = Mesh(rollout_devices, axis_names=('fsdp', 'tp'))\n",
    "train_mesh = Mesh(train_devices, axis_names=('fsdp', 'tp'))\n",
    "\n",
    "config = model_lib.ModelConfig.deepseek_r1_distill_qwen_1p5b()\n",
    "qwen2_actor = params_lib.create_model_from_safe_tensors(MODEL_PATH, config, train_mesh, dtype=jnp.float32)\n",
    "qwen2_ref = params_lib.create_model_from_safe_tensors(MODEL_PATH, config, train_mesh, dtype=jnp.float32)\n",
    "sft_utils.show_hbm_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84e10de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tunix.generate import sampler\n",
    "\n",
    "sampler = sampler.Sampler(qwen2_actor, tokenizer, sampler.CacheConfig(cache_size=16384, num_layers=28, num_kv_heads=2, head_dim=128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f96f7e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ====== Data ======\n",
    "# TRAIN_FRACTION = 1.0\n",
    "\n",
    "# # ====== Reproducibility ======\n",
    "# SEED = 42\n",
    "\n",
    "# # ====== LoRA ======\n",
    "# RANK = 64\n",
    "# ALPHA = 64.0\n",
    "# TRAIN_WITH_LORA = False\n",
    "\n",
    "# # ====== Sharding ======\n",
    "# MESH = [(2, 4), (\"fsdp\", \"tp\")]\n",
    "\n",
    "# # ====== GRPO ======\n",
    "# # === Generation during GRPO training ===\n",
    "# MAX_PROMPT_LENGTH = 2048\n",
    "# TOTAL_GENERATION_STEPS = 512\n",
    "# # Important to keep a high-ish temperature for varied, diverse responses during\n",
    "# # training.\n",
    "# TEMPERATURE = 0.6\n",
    "# TOP_P = 0.95\n",
    "# TOP_K = 50\n",
    "# # The number of times the policy generates multiple responses for a given prompt\n",
    "# # within a single training step. This corresponds to `G` in Algorithm 1 in the\n",
    "# # paper. The \"group\" in GRPO comes from here.\n",
    "# NUM_GENERATIONS = 2\n",
    "\n",
    "# # === other GRPO configs ===\n",
    "# # The number of iterations per batch (ùúá in GRPO algo 1).\n",
    "# NUM_ITERATIONS = 1\n",
    "# # The coefficient for the KL divergence penalty (ùõΩ) in the GRPO loss function.\n",
    "# # Important to keep a high enough value for this, otherwise, the KL divergence\n",
    "# # can increase unchecked.\n",
    "# BETA = 0.001\n",
    "# # Epsilon value for clipping (ùúÄ in GRPO loss in paper). Similar to PPO, for\n",
    "# # stable updates.\n",
    "# EPSILON = 0.2\n",
    "\n",
    "# # ====== Training ======\n",
    "# BATCH_SIZE = 16\n",
    "# MINI_BATCH_SIZE = 16\n",
    "# # ROLLOUT_MICRO_BATCH_SIZE = 8\n",
    "# # LOGPS_MICRO_BATCH_SIZE = 8\n",
    "# NUM_BATCHES = 100\n",
    "# # Keep `NUM_TEST_BATCHES` low so that evaluation runs quickly. It can be\n",
    "# # increased to a max. of 330 (if batch size is 4).\n",
    "# NUM_TEST_BATCHES = 50\n",
    "\n",
    "# EVAL_EVERY_N_STEPS = 1000  # this doesn't matter if `TRAIN_FRACTION = 1.0`.\n",
    "# NUM_EPOCHS = 100 # can potentially train for more epochs\n",
    "\n",
    "# # Number of training steps.\n",
    "# MAX_STEPS = int(NUM_BATCHES * NUM_ITERATIONS * TRAIN_FRACTION * NUM_EPOCHS)\n",
    "\n",
    "# # === AdamW, warmup, cosine scheduler ===\n",
    "# LEARNING_RATE = 1e-6\n",
    "# B1 = 0.9  # Adam beta1\n",
    "# B2 = 0.99  # Adam beta2\n",
    "# WEIGHT_DECAY = 0.1\n",
    "# # == Cosine decay with warmup scheduler ==\n",
    "# # Linearly increase learning rate from 0. to 5e-6 in the first 10% training\n",
    "# # steps, and then gradually decrease the learning rate to 0 using cosine\n",
    "# # scheduler.\n",
    "# WARMUP_STEPS = int(0.1 * MAX_STEPS)\n",
    "# # == Grad clipping ==\n",
    "# # Grad clipping to prevent large gradients. Found this\n",
    "# # important to keep KL divergence in check.\n",
    "# MAX_GRAD_NORM = 0.1\n",
    "\n",
    "# # ====== Checkpoint saving ======\n",
    "# SAVE_INTERVAL_STEPS = 500\n",
    "# MAX_TO_KEEP = 4\n",
    "# DO_MEM_PROFILING = False\n",
    "\n",
    "# # ====== Inference ======\n",
    "# GENERATION_CONFIGS = {\n",
    "#     # greedy search\n",
    "#     \"greedy\": {\"temperature\": 1e-4, \"top_k\": 1, \"top_p\": 1.0},\n",
    "#     # some randomness\n",
    "#     \"standard\": {\"temperature\": 0.7, \"top_k\": 50, \"top_p\": 0.95},\n",
    "#     # liberal\n",
    "#     \"liberal\": {\"temperature\": 0.85, \"top_k\": 2000, \"top_p\": 1.0},\n",
    "# }\n",
    "# # ====== Rollout ======\n",
    "# ROLLOUT_ENGINE = \"sglang_jax\" # one of \"vanilla\", \"vllm\" or \"sglang_jax\"\n",
    "\n",
    "# CKPT_DIR = os.path.join(\"/tmp/cp\", \"deepscaler_ckpt/01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a442695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tunix.rl import rl_cluster as rl_cluster_lib\n",
    "# import optax\n",
    "# from tunix.sft import metrics_logger\n",
    "# from orbax import checkpoint as ocp\n",
    "# from tunix.rl.rollout import base_rollout\n",
    "\n",
    "# checkpointing_options = ocp.CheckpointManagerOptions(\n",
    "#     save_interval_steps=SAVE_INTERVAL_STEPS, max_to_keep=MAX_TO_KEEP\n",
    "# )\n",
    "# metrics_logging_options = metrics_logger.MetricsLoggerOptions(\n",
    "#     log_dir=\"/tmp/tensorboard/grpo\", flush_every_n_steps=20\n",
    "# )\n",
    "\n",
    "# optimizer = optax.adamw(\n",
    "#     learning_rate=optax.schedules.warmup_cosine_decay_schedule(\n",
    "#         init_value=0.0,\n",
    "#         peak_value=LEARNING_RATE,\n",
    "#         warmup_steps=WARMUP_STEPS,\n",
    "#         decay_steps=MAX_STEPS,\n",
    "#         end_value=0.0,\n",
    "#     ),\n",
    "#     b1=B1,\n",
    "#     b2=B2,\n",
    "#     weight_decay=WEIGHT_DECAY,\n",
    "# )\n",
    "\n",
    "# cluster_config = rl_cluster_lib.ClusterConfig(\n",
    "#     role_to_mesh={\n",
    "#         rl_cluster_lib.Role.ACTOR: train_mesh,\n",
    "#         rl_cluster_lib.Role.REFERENCE: train_mesh,\n",
    "#         rl_cluster_lib.Role.ROLLOUT: rollout_mesh,\n",
    "#     },\n",
    "#     rollout_engine=ROLLOUT_ENGINE,\n",
    "#     offload_to_cpu=False,\n",
    "#     training_config=rl_cluster_lib.RLTrainingConfig(\n",
    "#         actor_optimizer=optimizer,\n",
    "#         eval_every_n_steps=EVAL_EVERY_N_STEPS,\n",
    "#         max_steps=20,\n",
    "#         mini_batch_size=MINI_BATCH_SIZE,\n",
    "#         train_micro_batch_size = 1,  # larger than 1 will cause OOM on HBM\n",
    "#         # metrics logging\n",
    "#         metrics_logging_options=metrics_logging_options,\n",
    "#         # checkpoint saving\n",
    "#         checkpoint_root_directory=CKPT_DIR,\n",
    "#         checkpointing_options=checkpointing_options,\n",
    "#     ),\n",
    "#     rollout_config=base_rollout.RolloutConfig(\n",
    "#         max_tokens_to_generate=TOTAL_GENERATION_STEPS,\n",
    "#         max_prompt_length=MAX_PROMPT_LENGTH,\n",
    "#         kv_cache_size=MAX_PROMPT_LENGTH + TOTAL_GENERATION_STEPS + 256,\n",
    "#         temperature=TEMPERATURE,\n",
    "#         top_p=TOP_P,\n",
    "#         top_k=TOP_K,\n",
    "#         eos_tokens=[tokenizer.encode(\"<|im_end|>\")[0]],\n",
    "#         # sglang-jax specific configs\n",
    "#         rollout_sglang_jax_model_version=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "#         rollout_sglang_jax_mem_fraction_static=0.2,\n",
    "#         rollout_sglang_jax_init_with_random_weights=True,\n",
    "#         rollout_sglang_jax_disable_radix_cache=True,\n",
    "#         rollout_sglang_jax_enable_deterministic_sampling=False,\n",
    "#         rollout_sglang_jax_precompile_bs_paddings=[1, 2],\n",
    "#         rollout_sglang_jax_precompile_token_paddings=[2048, 4096, 8192],\n",
    "#         rollout_sglang_jax_chunked_prefill_size=2048,\n",
    "#         rollout_sglang_jax_page_size=64,\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# rl_cluster = rl_cluster_lib.RLCluster(\n",
    "#     actor=qwen2_actor,\n",
    "#     reference=qwen2_ref,\n",
    "#     tokenizer=tokenizer,\n",
    "#     cluster_config=cluster_config,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b1f66fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a programming agent who is provided a github issue and repository bash environment and is tasked to solve certain tasks (e.g., file localization, testcase generation, code repair and editing etc) to resolve the issue.\n",
      "\n",
      "We have access to the following functions:\n",
      "\n",
      "‚Äì‚Äì BEGIN FUNCTION #1: file_editor ‚Äì‚Äì\n",
      "Description:\n",
      "Custom editing tool for viewing, creating and editing files\n",
      "  ‚Ä¢\tState is persistent across command calls and discussions with the user\n",
      "  ‚Ä¢\tIf path is a file, view displays the result of applying cat -n. If path is a directory, view lists non-hidden files and directories up to 2 levels deep\n",
      "  ‚Ä¢\tThe create command cannot be used if the specified path already exists as a file\n",
      "  ‚Ä¢\tIf a command generates a long output, it will be truncated and marked with <response clipped>\n",
      "  ‚Ä¢\tThe undo_edit command will revert the last edit made to the file at path\n",
      "\n",
      "Notes for using the str_replace command:\n",
      "  ‚Ä¢\tThe old_str parameter should match EXACTLY one or more consecutive lines from the original file. Be mindful of whitespaces!\n",
      "  ‚Ä¢\tIf the old_str parameter is not unique in the file, the replacement will not be performed. Make sure to include enough context in old_str to make it unique\n",
      "  ‚Ä¢\tThe new_str parameter should contain the edited lines that should replace the old_str\n",
      "\n",
      "Parameters:\n",
      "  1.\tcommand (string, required)\n",
      "Allowed values: [view, create, str_replace, insert, undo_edit]\n",
      "The command to run.\n",
      "  2.\tpath (string, required)\n",
      "Absolute path to file or directory, e.g. /testbed/file.py or /testbed.\n",
      "  3.\tfile_text (string, optional)\n",
      "Required for the create command. Contains the content of the file to be created.\n",
      "  4.\told_str (string, optional)\n",
      "Required for the str_replace command. The exact string in path to replace.\n",
      "  5.\tnew_str (string, optional)\n",
      "  ‚Ä¢\tOptional for the str_replace command to specify the replacement string.\n",
      "  ‚Ä¢\tRequired for the insert command to specify the string to insert.\n",
      "  6.\tinsert_line (integer, optional)\n",
      "Required for the insert command. The new_str will be inserted after the line number specified here.\n",
      "  7.\tview_range (array, optional)\n",
      "  ‚Ä¢\tOptional for the view command (when path is a file).\n",
      "  ‚Ä¢\tIf provided, specifies the line range to view, e.g. [11, 12] shows lines 11 and 12.\n",
      "  ‚Ä¢\t[start_line, -1] will show all lines from start_line to the end of file.\n",
      "  8.\tconcise (boolean, optional)\n",
      "  ‚Ä¢\tOptional for the view command.\n",
      "  ‚Ä¢\tDefaults to True; displays a concise skeletal view of the file. If set to False, displays the full content in the specified view_range.\n",
      "\n",
      "‚Äì‚Äì END FUNCTION #1 ‚Äì‚Äì\n",
      "\n",
      "‚Äì‚Äì BEGIN FUNCTION #2: execute_bash ‚Äì‚Äì\n",
      "Description:\n",
      "Execute a bash command in the terminal.\n",
      "\n",
      "Behavior notes:\n",
      "  ‚Ä¢\tIf a command may run indefinitely (long-running), consider running it in the background and redirecting output, e.g. python3 app.py > server.log 2>&1 &.\n",
      "  ‚Ä¢\tIf the bash command returns exit code -1, it means the process is still running. The assistant may:\n",
      "  ‚Ä¢\tCall this function again with command as an empty string (\"\") to retrieve additional logs.\n",
      "  ‚Ä¢\tSend more input to STDIN of the running process by calling this function again with command set to the text input.\n",
      "  ‚Ä¢\tSend command=\"ctrl+c\" to interrupt the currently running process.\n",
      "  ‚Ä¢\tIf the command times out, it will be interrupted (SIGINT). The assistant may then retry or do further steps if needed.\n",
      "\n",
      "Parameters:\n",
      "  1.\tcmd (string, required)\n",
      "The bash command (and optional arguments) to execute.\n",
      "  ‚Ä¢\tCan be empty (\"\") to retrieve more logs if the process is still running.\n",
      "  ‚Ä¢\tCan be \"ctrl+c\" to interrupt the running process.\n",
      "\n",
      "‚Äì‚Äì END FUNCTION #2 ‚Äì‚Äì\n",
      "\n",
      "‚Äì‚Äì BEGIN FUNCTION #3: search ‚Äì‚Äì\n",
      "Description:\n",
      "Search for a term in a directory or a single file.\n",
      "  ‚Ä¢\tIf path is a directory (or unspecified, default is .), it recursively searches all non-hidden files and directories for the search term.\n",
      "  ‚Ä¢\tIf path points to a file, it runs a grep -n in that file to show line numbers matching the search term.\n",
      "  ‚Ä¢\tIf more than 100 files match in a directory search, results are truncated and the tool will inform you to narrow your search.\n",
      "  ‚Ä¢\tIf no matches are found, it will inform you as well.\n",
      "\n",
      "Parameters:\n",
      "  1.\tsearch_term (string, required)\n",
      "The term or string to search for in files.\n",
      "  2.\tpath (string, optional)\n",
      "The file or directory to search in. Defaults to . if not specified.\n",
      "\n",
      "‚Äì‚Äì END FUNCTION #3 ‚Äì‚Äì\n",
      "\n",
      "‚Äì‚Äì BEGIN FUNCTION #4: finish ‚Äì‚Äì\n",
      "Description:\n",
      "Finish the interaction once the task is complete or if no further progress can be made.\n",
      "\n",
      "Behavior notes:\n",
      "  ‚Ä¢\tThe submit command finalizes your output.\n",
      "\n",
      "Parameters:\n",
      "  1.\tcommand (string, required)\n",
      "Currently allowed value: [submit]\n",
      "  2.\tresult (string, optional)\n",
      "The result text or final message to submit. Defaults to an empty string if not provided.\n",
      "\n",
      "‚Äì‚Äì END FUNCTION #4 ‚Äì‚Äì\n",
      "\n",
      "If you choose to call a function ONLY reply in the following format with NO suffix:\n",
      "\n",
      "<function=example_function_name>\n",
      "<parameter=example_parameter_1>value_1</parameter>\n",
      "<parameter=example_parameter_2>\n",
      "This is the value for the second parameter\n",
      "that can span\n",
      "multiple lines\n",
      "</parameter>\n",
      "</function>\n",
      "\n",
      "<IMPORTANT>\n",
      "Reminder:\n",
      "- Function calls MUST follow the specified format, start with <function= and end with </function>\n",
      "- Required parameters MUST be specified\n",
      "- Only call one function at a time\n",
      "- VERY IMPORTANT: Each response must include both reasoning (as natural text) and function call (in above format) to solve the task.\n",
      "<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from swe_agent import SWEAgent\n",
    "from swe_env import SWEEnv\n",
    "from tunix.rl.agentic.trajectory import trajectory_collect_engine\n",
    "from tunix.rl.agentic.parser.chat_template_parser.parser import QwenChatTemplateParser\n",
    "from tunix.rl.agentic.rewards.reward_types import RewardOutput\n",
    "\n",
    "chat_parser = QwenChatTemplateParser(tokenizer)\n",
    "\n",
    "# def model_call(chat_lists, rl_cluster):\n",
    "#     result = rl_cluster.generate(\n",
    "#         prompts=chat_lists,\n",
    "#         apply_chat_template=True,\n",
    "#         mode=rl_cluster_lib.Mode.TRAIN,\n",
    "#     )\n",
    "#     return result.text[0]\n",
    "\n",
    "def model_call(chat_completions, _):\n",
    "    p = chat_parser.parse(chat_completions)\n",
    "    out = sampler(p, max_generation_steps=128, echo=False)\n",
    "    return out.text[0]\n",
    "\n",
    "agent = SWEAgent()\n",
    "env = SWEEnv(entry=entries[0])\n",
    "\n",
    "print(chat_parser.parse(agent.chat_completions))\n",
    "\n",
    "engine = trajectory_collect_engine.TrajectoryCollectEngine(\n",
    "    agent=agent,\n",
    "    env=env,\n",
    "    model_call=model_call,\n",
    "    final_reward_fn=lambda x, y: RewardOutput(reward=0, metadata={}),\n",
    "    max_steps=5,\n",
    "    gamma=0.9,\n",
    ")\n",
    "\n",
    "\n",
    "# res = await engine.collect(mode=\"Trajectory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f51e7940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created env\n",
      "inital obs: \n",
      "**Title:** Context migration fails to remove incompatible contexts, causing initialization errors\n",
      "\n",
      "**Description:**\n",
      "When initializing the `ContextHandler` with a mix of compatible and incompatible contexts, the migration process does not remove the incompatible contexts as expected. Instead, it raises an `IncompatibleContext` error, preventing successful initialization.\n",
      "\n",
      "**Example Code:**\n",
      "```python\n",
      "handler = ContextHandler()\n",
      "handler.bind(SimpleWidget)\n",
      "\n",
      "widget = SimpleWidget()\n",
      "contexts = [Context(foo=i) for i in (13, 13, 0, 1, 13, 2, 13)]\n",
      "\n",
      "def migrate_context(context, _):\n",
      "    if context.foo == 13:\n",
      "        raise IncompatibleContext()\n",
      "\n",
      "handler.initialize(widget, dict(context_settings=contexts))\n",
      "# Expected: Incompatible contexts with foo=13 should be removed\n",
      "# Actual: IncompatibleContext error is raised, and contexts are not removed\n",
      "```\n",
      "\n",
      "**Expected Behavior:**\n",
      "During initialization, contexts that are incompatible (e.g., those that cause `IncompatibleContext` to be raised) should be automatically removed, allowing the `ContextHandler` to proceed with only the compatible contexts.\n",
      "\n",
      "**Actual Behavior:**\n",
      "The `ContextHandler` does not remove incompatible contexts, resulting in an `IncompatibleContext` error being raised and preventing successful initialization.\n",
      "\n",
      "\n",
      "didn't find any funciton to call\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Remove existing handlers to prevent duplicate logs or conflicts\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout,  # Direct logs to standard output (notebook cell)\n",
    "    level=logging.INFO, # Set the minimum level to INFO\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\", # Optional: customize the format\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\" # Optional: customize the date format\n",
    ")\n",
    "\n",
    "res = await engine.collect(mode='Trajectory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4914c3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"</im_end>\\n\\n</think>\\n\\nTo fix the issue where incompatible contexts are not being removed during context migration, we need to modify the `ContextHandler` class to check for incompatible contexts before initializing. Here's the step-by-step solution:\\n\\n1. **Modify the `initialize` method**:\\n   - Add a check to see if any context in the provided contexts has a `foo` value that matches any context in the handler.\\n   - If a match is found, remove that context from the handler.\\n\\nHere's the code change:\\n\\n```python\\nclass ContextHandler:\\n    def __init__(self, context_settings=None):\\n        self.context\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(env.total_steps)\n",
    "res.steps[0].model_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05ebc54",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f8fa0f0",
   "metadata": {},
   "source": [
    "# Random stuff for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4736e6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/26/26 17:34:04] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Kubernetes pod <span style=\"color: #008000; text-decoration-color: #008000\">'58536a8d-40f2-4531-8a91-1f6b3fb34470'</span> is Running.                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/26/26 17:34:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Kubernetes pod \u001b[32m'58536a8d-40f2-4531-8a91-1f6b3fb34470'\u001b[0m is Running.                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/26/26 17:34:09] </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR   </span> Kubernetes exec Error: Exit code <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                                    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Error Message: mv: cannot stat <span style=\"color: #008000; text-decoration-color: #008000\">'/testbed/r2e_tests'</span>: No such file or directory        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/26/26 17:34:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m Kubernetes exec Error: Exit code \u001b[1;36m1\u001b[0m                                                    \n",
       "\u001b[2;36m                    \u001b[0m         Error Message: mv: cannot stat \u001b[32m'/testbed/r2e_tests'\u001b[0m: No such file or directory        \n",
       "\u001b[2;36m                    \u001b[0m                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Kubernetes environment initialized                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Kubernetes environment initialized                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> repo name: orange3                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m repo name: orange3                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Docker image: namanjain12/orange3_final:2d9617bd0cb1f0ba61771258410ab8fae8e7e24d      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Docker image: namanjain12/orange3_final:2d9617bd0cb1f0ba61771258410ab8fae8e7e24d      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Pod Name: <span style=\"color: #ffff00; text-decoration-color: #ffff00\">58536a8d-40f2-4531-8a91-1f6b3fb34470</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Pod Name: \u001b[93m58536a8d-40f2-4531-8a91-1f6b3fb34470\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# runtime = DockerRuntime(ds=entries[0], command=[\"/bin/bash\", \"-l\"], logger=get_logger(), backend=\"kubernetes\", id=IDS[0])\n",
    "# runtime.get_task_instruction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d36129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/26/26 17:35:20] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Confirmed pod <span style=\"color: #ffff00; text-decoration-color: #ffff00\">58536a8d-40f2-4531-8a91-1f6b3fb34470</span> is deleted.                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/26/26 17:35:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Confirmed pod \u001b[93m58536a8d-40f2-4531-8a91-1f6b3fb34470\u001b[0m is deleted.                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# runtime.run(code=\"ls -l\")\n",
    "# runtime.stop_container()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cee4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOCKER_PATH = \"/root/.venv/bin:/root/.local/bin:/root/.cargo/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n",
    "# pod_name = \"tsbao-test-cpu-pod\"\n",
    "# docker_image = entries[0][\"docker_image\"]\n",
    "# command = \"/bin/bash\"\n",
    "\n",
    "# env_vars = {\"PATH\": DOCKER_PATH}\n",
    "# env_spec = [{\"name\": k, \"value\": str(v)} for k, v in env_vars.items()]\n",
    "# pod_body = {\n",
    "#     \"apiVersion\": \"v1\",\n",
    "#     \"kind\": \"Pod\",\n",
    "#     \"metadata\": {\"name\": pod_name},\n",
    "#     \"spec\": {\n",
    "#         \"restartPolicy\": \"Never\",\n",
    "#         \"containers\": [\n",
    "#             {\n",
    "#                 \"name\": pod_name,\n",
    "#                 \"image\": docker_image,\n",
    "#                 \"command\": [\"/bin/sh\", \"-c\"],\n",
    "#                 \"args\": [command] if isinstance(command, str) else command,\n",
    "#                 \"stdin\": True,\n",
    "#                 \"tty\": True,\n",
    "#                 \"env\": env_spec,\n",
    "#                 \"resources\": {\n",
    "#                     \"requests\": {\"cpu\": \"1\", \"memory\": \"1Gi\"},\n",
    "#                 },\n",
    "#             }\n",
    "#         ],\n",
    "#         \"imagePullSecrets\": [{\"name\": \"dockerhub-pro\"}],\n",
    "#         \"nodeSelector\": {\"cloud.google.com/gke-nodepool\": \"tsbao-cpu-pool\"},\n",
    "#         \"tolerations\": [\n",
    "#             {\n",
    "#                 \"key\": \"node.kubernetes.io/disk-pressure\",\n",
    "#                 \"operator\": \"Exists\",\n",
    "#                 \"effect\": \"NoExecute\",\n",
    "#                 \"tolerationSeconds\": 10800\n",
    "#             }\n",
    "#         ],\n",
    "#     },\n",
    "# }\n",
    "\n",
    "pod = k8s_client.create_namespaced_pod(\n",
    "    namespace=\"default\", body=pod_body, _request_timeout=60,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f85a862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k8s_client.list_namespaced_pod(namespace=\"default\")\n",
    "pod_name = \"tsbao-test-pod\"\n",
    "pod = k8s_client.read_namespaced_pod(name=pod_name, namespace=\"default\")\n",
    "pod.status.phase\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfaa1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kubernetes.stream.ws_client.WSClient at 0x78b19a7390f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from kubernetes.stream import stream\n",
    "\n",
    "# full_command = [\"/bin/sh\", \"-c\", \"ls -l\"]\n",
    "# resp = stream(\n",
    "#     k8s_client.connect_get_namespaced_pod_exec,\n",
    "#     name=pod_name,\n",
    "#     namespace=\"default\",\n",
    "#     command=full_command,\n",
    "#     stderr=True,\n",
    "#     stdin=False,\n",
    "#     stdout=True,\n",
    "#     tty=False,  # Match docker exec_run settings\n",
    "#     _preload_content=False,  # Important for streaming\n",
    "# )\n",
    "# resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd00a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_chunks = []\n",
    "# stdout_chunks = []\n",
    "# stderr_chunks = []\n",
    "# while resp.is_open():\n",
    "#     resp.update(timeout=1)  # wait for data\n",
    "#     if resp.peek_stdout():\n",
    "#         chunk = resp.read_stdout()\n",
    "#         stdout_chunks.append(chunk)\n",
    "#         combined_chunks.append(chunk)\n",
    "#     if resp.peek_stderr():\n",
    "#         chunk = resp.read_stderr()\n",
    "#         stderr_chunks.append(chunk)\n",
    "#         combined_chunks.append(chunk)\n",
    "# resp.close()\n",
    "# exit_code = resp.returncode\n",
    "# combined_output = \"\".join(combined_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dab136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Command(code='#!/root/.venv/bin/python\\n\\n\"\"\"\\nDescription: Custom editing tool for viewing, creating and editing files\\n* State is persistent across command calls and discussions with the user\\n* If `path` is a file, `view` displays the result of applying `cat -n`. If `path` is a directory, `view` lists non-hidden files and directories up to 2 levels deep\\n* The `create` command cannot be used if the specified `path` already exists as a file\\n* If a `command` generates a long output, it will be truncated and marked with `<response clipped>`\\n* The `undo_edit` command will revert the last edit made to the file at `path`\\n\\nNotes for using the `str_replace` command:\\n* The `old_str` parameter should match EXACTLY one or more consecutive lines from the original file. Be mindful of whitespaces!\\n* If the `old_str` parameter is not unique in the file, the replacement will not be performed. Make sure to include enough context in `old_str` to make it unique\\n* The `new_str` parameter should contain the edited lines that should replace the `old_str`\\n\\nParameters:\\n  (1) command (string, required): The commands to run. Allowed options are: `view`, `create`, `str_replace`, `insert`, `undo_edit`.\\nAllowed values: [`view`, `create`, `str_replace`, `insert`, `undo_edit`]\\n  (2) path (string, required): Absolute path to file or directory, e.g. `/testbed/file.py` or `/testbed`.\\n  (3) file_text (string, optional): Required parameter of `create` command, with the content of the file to be created.\\n  (4) old_str (string, optional): Required parameter of `str_replace` command containing the string in `path` to replace.\\n  (5) new_str (string, optional): Optional parameter of `str_replace` command containing the new string (if not given, no string will be added). Required parameter of `insert` command containing the string to insert.\\n  (6) insert_line (integer, optional): Required parameter of `insert` command. The `new_str` will be inserted AFTER the line `insert_line` of `path`.\\n  (7) view_range (array, optional): Optional parameter of `view` command when `path` points to a file. If none is given, the full file is shown. If provided, the file will be shown in the indicated line number range, e.g. [11, 12] will show lines 11 and 12. Indexing at 1 to start. Setting `[start_line, -1]` shows all lines from `start_line` to the end of the file.\\n  (8) enable_linting (boolean, optional): Optional parameter to enable Python linting checks before saving changes. Default is `false`.\\n  (9) concise (boolean, optional): Optional parameter to enable a condensed view for Python files. Default is `false`. Super useful for understanding the structure of a Python file without getting bogged down in the details.\\n\"\"\"\\n\\nimport argparse\\nimport json\\nimport subprocess\\nfrom pathlib import Path\\nfrom collections import defaultdict\\nfrom typing import Dict, List, Tuple, Optional\\nimport warnings\\n\\nimport sys\\nimport chardet\\n\\n# sys.stdout.reconfigure(encoding=\\'utf-8\\')\\n\\nSTATE_FILE = \"/var/tmp/editor_state.json\"\\nSNIPPET_LINES = 4\\n\\n# We ignore certain warnings from tree_sitter (optional).\\nwarnings.simplefilter(\"ignore\", category=FutureWarning)\\n\\n_LINT_ERROR_TEMPLATE = \"\"\"Your proposed edit has introduced new syntax error(s).\\nPlease read this error message carefully and then retry editing the file.\\nERRORS:\\n\"\"\"\\n\\nTRUNCATED_MESSAGE = (\\n    \"<response clipped><NOTE>To save on context only part of this file has been \"\\n    \"shown to you. You should retry this tool after you have searched inside the file \"\\n    \"with `grep -n` in order to find the line numbers of what you are looking for.</NOTE>\"\\n)\\nMAX_RESPONSE_LEN = 10000  # 4000 #12000 # 16000\\n\\n\\nimport sys\\nimport io\\n\\n# sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding=\"utf-8\")\\nif hasattr(sys.stdout, \\'buffer\\'):\\n    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding=\"utf-8\")\\nelse:\\n    # Fallback\\n    sys.stderr.write(\"sys.stdout does not have a \\'buffer\\' attribute.\\\\n\")\\n\\n\\ndef safe_print(x):\\n    try:\\n        print(x)\\n    except UnicodeEncodeError:\\n        print(x.encode(\"utf-8\", errors=\"replace\").decode(\"utf-8\", errors=\"replace\"))\\n\\n\\ndef maybe_truncate(content: str, truncate_after: Optional[int] = MAX_RESPONSE_LEN):\\n    if not truncate_after or len(content) <= truncate_after:\\n        return content\\n    return content[:truncate_after] + TRUNCATED_MESSAGE\\n\\n\\nclass EditorError(Exception):\\n    \"\"\"Raised for usage or file system errors within the editor tool.\"\"\"\\n\\n\\nclass EditorResult:\\n    \"\"\"\\n    Simple container for output and optional error messages.\\n    \"\"\"\\n\\n    def __init__(self, output: str, error: str = \"\"):\\n        self.output = output\\n        self.error = error\\n\\n    def __str__(self):\\n        if self.error:\\n            return f\"ERROR: {self.error}\\\\n\\\\n{self.output}\"\\n        return self.output\\n\\n\\ndef load_history() -> Dict[str, List[str]]:\\n    \"\"\"\\n    Load the file edit history from STATE_FILE if it exists.\\n    \"\"\"\\n    try:\\n        with open(STATE_FILE, \"r\", encoding=\"utf-8\") as f:\\n            data = json.load(f)\\n            return {k: v for k, v in data.items()}\\n    except FileNotFoundError:\\n        return {}\\n    except Exception as e:\\n        safe_print(f\"Warning: Could not load editor history from {STATE_FILE}: {e}\")\\n        return {}\\n\\n\\ndef save_history(history: Dict[str, List[str]]):\\n    \"\"\"\\n    Save the file edit history to STATE_FILE as JSON.\\n    \"\"\"\\n    try:\\n        with open(STATE_FILE, \"w\", encoding=\"utf-8\") as f:\\n            json.dump(history, f)\\n    except Exception as e:\\n        safe_print(f\"Warning: Could not write editor history to {STATE_FILE}: {e}\")\\n\\n\\nclass StrReplaceEditor:\\n    \"\"\"\\n    A file editor that supports the following commands:\\n        - view\\n        - create\\n        - str_replace\\n        - insert\\n        - undo_edit\\n\\n    The edit history is kept in memory (self.file_history) and also persisted to disk.\\n\\n    Additionally, a `--concise` option for `view` on Python files:\\n    - Uses tree-sitter to skip large function bodies.\\n    - Preserves original line numbering, printing placeholders for elided lines.\\n    \"\"\"\\n\\n    def __init__(\\n        self, file_history: Dict[str, List[str]], enable_linting: bool = False\\n    ):\\n        self.file_history = defaultdict(list, file_history)\\n        self.enable_linting = enable_linting\\n\\n    def run(\\n        self,\\n        command: str,\\n        path_str: str,\\n        file_text: str = None,\\n        view_range: List[int] = None,\\n        old_str: str = None,\\n        new_str: str = None,\\n        insert_line: int = None,\\n        concise: bool = False,\\n        python_only: bool = True,\\n    ) -> EditorResult:\\n        path = Path(path_str)\\n        self.validate_path(command, path)\\n\\n        if command == \"view\":\\n            return self.view(path, view_range, concise=concise, python_only=python_only)\\n        elif command == \"create\":\\n            return self.create(path, file_text)\\n        elif command == \"str_replace\":\\n            return self.str_replace(path, old_str, new_str)\\n        elif command == \"insert\":\\n            return self.insert(path, insert_line, new_str)\\n        elif command == \"undo_edit\":\\n            return self.undo_edit(path)\\n        else:\\n            raise EditorError(\\n                f\"Unrecognized command \\'{command}\\'. \"\\n                \"Allowed commands: view, create, str_replace, insert, undo_edit.\"\\n            )\\n\\n    def validate_path(self, command: str, path: Path):\\n        if command == \"create\":\\n            if path.exists():\\n                raise EditorError(\\n                    f\"File already exists at: {path}. Cannot overwrite with \\'create\\'.\"\\n                )\\n        else:\\n            if not path.exists():\\n                raise EditorError(f\"The path \\'{path}\\' does not exist.\")\\n\\n        if path.is_dir() and command != \"view\":\\n            raise EditorError(\\n                f\"The path \\'{path}\\' is a directory. Only \\'view\\' can be used on directories.\"\\n            )\\n\\n    @staticmethod\\n    def read_path(path: Path) -> str:\\n        encoding = chardet.detect(path.read_bytes())[\"encoding\"]\\n        if encoding is None:\\n            encoding = \"utf-8\"\\n        return path.read_text(encoding=encoding)\\n\\n    def view(\\n        self,\\n        path: Path,\\n        view_range: Optional[List[int]] = None,\\n        concise: bool = False,\\n        python_only: bool = True,\\n    ) -> EditorResult:\\n        \"\"\"\\n        If path is a directory, list contents (2 levels deep, excluding hidden).\\n        If path is a file, optionally use the \\'concise\\' approach for Python.\\n        Then apply [start_line, end_line] slicing if provided.\\n        \"\"\"\\n        if path.is_dir():\\n            if not python_only:\\n                cmd = [\"find\", str(path), \"-maxdepth\", \"2\", \"-not\", \"-path\", \"*/.*\"]\\n            else:\\n                # Use `-type d -o -name \\'*.py\\'` to only list directories or *.py files\\n                cmd = [\\n                    \"find\",\\n                    str(path),\\n                    \"-maxdepth\",\\n                    \"2\",\\n                    \"-not\",\\n                    \"-path\",\\n                    \"*/.*\",\\n                    \"(\",\\n                    \"-type\",\\n                    \"d\",\\n                    \"-o\",\\n                    \"-name\",\\n                    \"*.py\",\\n                    \")\",\\n                ]\\n            try:\\n                # Try using the newer parameters first (Python 3.7+)\\n                try:\\n                    proc = subprocess.run(\\n                        cmd, capture_output=True, text=True, check=False\\n                    )\\n                except TypeError:\\n                    # Fallback for Python 3.5 and 3.6 where capture_output and text are not supported\\n                    proc = subprocess.run(\\n                        cmd,\\n                        stdout=subprocess.PIPE,\\n                        stderr=subprocess.PIPE,\\n                        universal_newlines=True,\\n                        check=False,\\n                    )\\n\\n                stderr = proc.stderr.strip()\\n                stdout = proc.stdout\\n                if stderr:\\n                    return EditorResult(output=\"\", error=stderr)\\n\\n                msg = (\\n                    f\"Here\\'s the files and directories up to 2 levels deep in {path}, \"\\n                    \"excluding hidden:\\\\n\" + stdout\\n                )\\n                msg = maybe_truncate(msg)\\n                return EditorResult(output=msg)\\n            except Exception as e:\\n                return EditorResult(\\n                    output=\"\",\\n                    error=f\"Ran into {e} while trying to list directory contents of {path}.\",\\n                )\\n\\n        # ====================\\n        # NEW RESTRICTION: only .py files are allowed for viewing\\n        if path.suffix != \".py\" and python_only:\\n            error_msg = (\\n                f\"ERROR: Viewing non-Python files is disallowed for saving context. \"\\n                f\"File \\'{path.name}\\' is not a .py file.\"\\n            )\\n            return EditorResult(output=\"\", error=error_msg)\\n        # ====================\\n\\n        # -----------------------------------------------\\n        # NEW LOGIC for deciding whether to use \\'concise\\' mode\\n        # -----------------------------------------------\\n        # If no view_range is given, user did NOT explicitly request \\'concise\\',\\n        # and we have a Python file with more than 50 lines => default to concise\\n        if path.suffix == \".py\" and not view_range and not concise:\\n            file_text_tmp = self.read_path(path)\\n            if len(file_text_tmp.splitlines()) > 110:\\n                concise = True\\n\\n        # For a file\\n        if path.suffix == \".py\" and concise:\\n            # Use the tree_sitter approach\\n            lines_with_original_numbers = self._get_elided_lines(path)\\n        else:\\n            # Normal reading\\n            file_text = self.read_path(path)\\n            lines_with_original_numbers = [\\n                (i, line) for i, line in enumerate(file_text.splitlines())\\n            ]\\n\\n        # Optionally slice by [start_line, end_line]\\n        total_lines = len(lines_with_original_numbers)\\n        if view_range and len(view_range) == 2:\\n            start, end = view_range\\n            if not (1 <= start <= total_lines):\\n                return EditorResult(\\n                    output=\"\",\\n                    error=(\\n                        f\"Invalid view_range {view_range}: start line must be in [1, {total_lines}]\"\\n                    ),\\n                )\\n            if end != -1 and (end < start or end > total_lines):\\n                return EditorResult(\\n                    output=\"\",\\n                    error=(\\n                        f\"Invalid view_range {view_range}: end must be >= start \"\\n                        f\"and <= {total_lines}, or -1 to view until end.\"\\n                    ),\\n                )\\n\\n            # Filter lines by 1-based index\\n            sliced_lines = []\\n            for i, text in lines_with_original_numbers:\\n                one_based = i + 1\\n                if one_based < start:\\n                    continue\\n                if end != -1 and one_based > end:\\n                    continue\\n                sliced_lines.append((i, text))\\n        else:\\n            # No slicing\\n            sliced_lines = lines_with_original_numbers\\n\\n        # Now produce a cat-like output (line numbering = i+1)\\n        if concise:\\n            final_output = f\"Here is a condensed view for file: {path}; [Note: Useful for understanding file structure in a concise manner. Please use specific view_range without concise cmd if you want to explore further into the relevant parts.]\\\\n\"\\n        else:\\n            final_output = (\\n                f\"Here\\'s the result of running `cat -n` on the file: {path}:\\\\n\"\\n            )\\n        # Then maybe truncate\\n        output_str_list = []\\n        for i, text in sliced_lines:\\n            # i is 0-based\\n            output_str_list.append(f\"{i+1:6d} {text}\")\\n\\n        final_output += \"\\\\n\".join(output_str_list)\\n        final_output = maybe_truncate(final_output)\\n        return EditorResult(output=final_output)\\n\\n    def _get_elided_lines(self, path: Path) -> List[Tuple[int, str]]:\\n        \"\"\"\\n        Parse the Python file with the built-in \\'ast\\' module to skip\\n        large function bodies (‚â• 5 lines).\\n        Return a list of (zero_based_line_idx, text).\\n        \"\"\"\\n        import ast\\n\\n        file_text = self.read_path(path)\\n        try:\\n            tree = ast.parse(file_text, filename=str(path))\\n        except SyntaxError as e:\\n            # Raise EditorError to make sure we handle it gracefully upstream\\n            raise EditorError(f\"Syntax error for file {path}: {e}\")\\n\\n        def max_lineno_in_subtree(n: ast.AST) -> int:\\n            m = getattr(n, \"lineno\", 0)\\n            for child in ast.iter_child_nodes(n):\\n                m = max(m, max_lineno_in_subtree(child))\\n            return m\\n\\n        # We\\'ll gather the line ranges for all large function bodies\\n        elide_line_ranges = []\\n        for node in ast.walk(tree):\\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)) and node.body:\\n                # Attempt to use end_lineno (Python 3.8+), else fallback\\n                last_stmt = node.body[-1]\\n                if hasattr(last_stmt, \"end_lineno\") and last_stmt.end_lineno:\\n                    # 0-based start of the body (first statement in the function)\\n                    body_start = node.body[0].lineno - 1\\n\\n                    body_end = last_stmt.end_lineno - 1\\n                else:\\n                    body_start = node.body[0].lineno - 1\\n\\n                    docstring = ast.get_docstring(node)\\n\\n                    if docstring:\\n                        num_docstring_lines = docstring.count(\"\\\\n\") + 1\\n                        body_start -= num_docstring_lines\\n\\n                    # Fallback: traverse the subtree to find max lineno\\n                    body_end = max_lineno_in_subtree(last_stmt) - 1\\n\\n                # Skip the body if spans ‚â• 5 lines\\n                if (body_end - body_start) >= 3:\\n                    elide_line_ranges.append((body_start, body_end))\\n\\n            if isinstance(node, ast.ClassDef) and node.body:\\n                # elide large docstrings for classes\\n                has_docstring1 = (\\n                    isinstance(node.body[0], ast.Expr)\\n                    and isinstance(node.body[0].value, ast.Constant)\\n                    and isinstance(node.body[0].value.value, str)\\n                )\\n                has_docstring2 = isinstance(node.body[0], ast.Expr) and isinstance(\\n                    node.body[0].value, ast.Str\\n                )\\n                has_docstring = has_docstring1 or has_docstring2\\n                if has_docstring:\\n                    if hasattr(node.body[0], \"end_lineno\") and node.body[0].end_lineno:\\n                        docstring_start = node.body[0].lineno - 1\\n                        docstring_end = node.body[0].end_lineno - 1\\n                    else:\\n                        docstring_start = node.lineno\\n                        docstring_end = max_lineno_in_subtree(node.body[0]) - 1\\n\\n                    if (docstring_end - docstring_start) >= 4:\\n                        elide_line_ranges.append(\\n                            (docstring_start + 1, docstring_end - 1)\\n                        )\\n\\n        # Build a set of lines to skip\\n        elide_lines = {\\n            line for (start, end) in elide_line_ranges for line in range(start, end + 1)\\n        }\\n\\n        # Add an \"elision notice\" at the beginning of each range\\n        elide_messages = [\\n            (start, f\"... eliding lines {start+1}-{end+1} ...\")\\n            for (start, end) in elide_line_ranges\\n        ]\\n\\n        # Lines we do keep\\n        all_lines = file_text.splitlines()\\n        keep_lines = [\\n            (i, line) for i, line in enumerate(all_lines) if i not in elide_lines\\n        ]\\n\\n        # Combine and sort by line index\\n        combined = elide_messages + keep_lines\\n        combined.sort(key=lambda x: x[0])\\n\\n        return combined\\n\\n    def create(self, path: Path, file_text: str) -> EditorResult:\\n        if file_text is None:\\n            raise EditorError(\"Cannot create file without \\'file_text\\' parameter.\")\\n\\n        if self.enable_linting and path.suffix == \".py\":\\n            lint_error = self._lint_check(file_text, str(path))\\n            if lint_error:\\n                return EditorResult(output=\"\", error=_LINT_ERROR_TEMPLATE + lint_error)\\n\\n        try:\\n            path.write_text(file_text, encoding=\"utf-8\")\\n            self.file_history[str(path)].append(\"\")\\n        except Exception as e:\\n            raise EditorError(f\"Error creating file at {path}: {e}\")\\n\\n        success_msg = f\"File created at {path}. \"\\n        success_msg += self._make_output(file_text, str(path))\\n        success_msg += \"Review the file and make sure that it is as expected. Edit the file if necessary.\"\\n\\n        return EditorResult(output=f\"{success_msg}\")\\n\\n    def str_replace(self, path: Path, old_str: str, new_str: str) -> EditorResult:\\n        if old_str is None:\\n            raise EditorError(\"Missing required parameter \\'old_str\\' for \\'str_replace\\'.\")\\n\\n        file_content = self.read_file(path)\\n        occurrences = file_content.count(old_str)\\n        if occurrences == 0:\\n            raise EditorError(\\n                f\"No occurrences of \\'{old_str}\\' found in {path} for replacement.\"\\n            )\\n        if occurrences > 1:\\n            raise EditorError(\\n                f\"Multiple occurrences of \\'{old_str}\\' found in {path}. \"\\n                \"Please ensure it is unique before using str_replace.\"\\n            )\\n\\n        old_text = file_content\\n        updated_text = file_content.replace(old_str, new_str if new_str else \"\")\\n\\n        if self.enable_linting and path.suffix == \".py\":\\n            lint_error = self._lint_check(updated_text, str(path))\\n            if lint_error:\\n                return EditorResult(output=\"\", error=_LINT_ERROR_TEMPLATE + lint_error)\\n\\n        self.file_history[str(path)].append(old_text)\\n        self.write_file(path, updated_text)\\n\\n        # Original snippet logic\\n        replacement_line = file_content.split(old_str)[0].count(\"\\\\n\")\\n        start_line = max(0, replacement_line - SNIPPET_LINES)\\n        end_line = replacement_line + SNIPPET_LINES + (new_str or \"\").count(\"\\\\n\")\\n        snippet = \"\\\\n\".join(updated_text.split(\"\\\\n\")[start_line : end_line + 1])\\n\\n        success_msg = f\"The file {path} has been edited. \"\\n        success_msg += self._make_output(\\n            snippet, f\"a snippet of {path}\", start_line + 1\\n        )\\n        success_msg += \"Review the changes and make sure they are as expected. Edit the file again if necessary.\"\\n\\n        return EditorResult(output=success_msg)\\n\\n    def insert(self, path: Path, insert_line: int, new_str: str) -> EditorResult:\\n        if new_str is None:\\n            raise EditorError(\"Missing required parameter \\'new_str\\' for \\'insert\\'.\")\\n\\n        old_text = self.read_file(path)\\n        file_text_lines = old_text.split(\"\\\\n\")\\n\\n        if insert_line < 0 or insert_line > len(file_text_lines):\\n            raise EditorError(\\n                f\"Invalid insert_line {insert_line}. Must be in [0, {len(file_text_lines)}].\"\\n            )\\n\\n        new_str_lines = new_str.split(\"\\\\n\")\\n        new_file_text_lines = (\\n            file_text_lines[:insert_line]\\n            + new_str_lines\\n            + file_text_lines[insert_line:]\\n        )\\n        updated_text = \"\\\\n\".join(new_file_text_lines)\\n\\n        if self.enable_linting and path.suffix == \".py\":\\n            lint_error = self._lint_check(updated_text, str(path))\\n            if lint_error:\\n                return EditorResult(output=\"\", error=_LINT_ERROR_TEMPLATE + lint_error)\\n\\n        self.file_history[str(path)].append(old_text)\\n        self.write_file(path, updated_text)\\n\\n        # Original snippet logic\\n        snippet_lines = (\\n            file_text_lines[max(0, insert_line - SNIPPET_LINES) : insert_line]\\n            + new_str_lines\\n            + file_text_lines[insert_line : insert_line + SNIPPET_LINES]\\n        )\\n        snippet = \"\\\\n\".join(snippet_lines)\\n\\n        success_msg = f\"The file {path} has been edited. \"\\n        success_msg += self._make_output(\\n            snippet,\\n            \"a snippet of the edited file\",\\n            max(1, insert_line - SNIPPET_LINES + 1),\\n        )\\n        success_msg += (\\n            \"Review the changes and make sure they are as expected \"\\n            \"(correct indentation, no duplicate lines, etc). Edit the file again if necessary.\"\\n        )\\n\\n        return EditorResult(output=success_msg)\\n\\n    def undo_edit(self, path: Path) -> EditorResult:\\n        path_str = str(path)\\n        if not self.file_history[path_str]:\\n            raise EditorError(f\"No previous edits found for {path} to undo.\")\\n\\n        old_text = self.file_history[path_str].pop()\\n        self.write_file(path, old_text)\\n\\n        return EditorResult(\\n            output=(\\n                f\"Last edit to {path} undone successfully. \"\\n                + self._make_output(old_text, str(path))\\n            )\\n        )\\n\\n    def read_file(self, path: Path) -> str:\\n        try:\\n            return self.read_path(path)\\n        except Exception as e:\\n            raise EditorError(f\"Failed to read file {path}: {e}\")\\n\\n    def write_file(self, path: Path, content: str):\\n        try:\\n            path.write_text(content, encoding=\"utf-8\")\\n        except Exception as e:\\n            raise EditorError(f\"Failed to write file {path}: {e}\")\\n\\n    def _make_output(\\n        self,\\n        file_content: str,\\n        file_descriptor: str,\\n        init_line: int = 1,\\n        expand_tabs: bool = True,\\n    ) -> str:\\n        \"\"\"\\n        Mimics cat -n style numbering, plus maybe_truncate to avoid huge outputs.\\n        \"\"\"\\n        file_content = maybe_truncate(file_content)\\n        if expand_tabs:\\n            file_content = file_content.expandtabs()\\n\\n        lines = file_content.split(\"\\\\n\")\\n        numbered = \"\\\\n\".join(\\n            f\"{i + init_line:6}\\\\t{line}\" for i, line in enumerate(lines)\\n        )\\n        return (\\n            f\"Here\\'s the result of running `cat -n` on {file_descriptor}:\\\\n\"\\n            + numbered\\n            + \"\\\\n\"\\n        )\\n\\n    def _lint_check(self, new_content: str, file_path: str) -> str:\\n        import ast\\n\\n        try:\\n            ast.parse(new_content, filename=file_path)\\n            return \"\"\\n        except SyntaxError as e:\\n            return str(e)\\n\\n\\ndef main():\\n    def parse_view_range(range_str: str):\\n        # Remove surrounding brackets if present\\n        range_str = range_str.strip().strip(\"[]()\")\\n\\n        # Split on commas or whitespace\\n        parts = range_str.replace(\",\", \" \").split()\\n\\n        if len(parts) != 2:\\n            raise argparse.ArgumentTypeError(f\"Expected two numbers, got: {range_str}\")\\n        try:\\n            start_line = int(parts[0])\\n            end_line = int(parts[1])\\n        except ValueError:\\n            raise argparse.ArgumentTypeError(f\"Could not convert {parts} to integers.\")\\n        return [start_line, end_line]\\n\\n    parser = argparse.ArgumentParser(\\n        description=(\\n            \"A disk-backed file editing tool (view, create, str_replace, insert, undo_edit) \"\\n            \"with optional linting. Also supports a \\'concise\\' view for Python files.\"\\n        )\\n    )\\n    parser.add_argument(\\n        \"command\",\\n        type=str,\\n        help=\"One of: view, create, str_replace, insert, undo_edit\",\\n    )\\n    parser.add_argument(\\n        \"--path\",\\n        type=str,\\n        help=\"Path to the target file or directory (absolute path recommended)\",\\n    )\\n    parser.add_argument(\\n        \"--file_text\",\\n        type=str,\\n        default=None,\\n        help=\"File content (for \\'create\\')\",\\n    )\\n    parser.add_argument(\\n        \"--view_range\",\\n        type=parse_view_range,\\n        default=None,\\n        help=\"Line range to view [start_line, end_line], use -1 for end.\",\\n    )\\n    parser.add_argument(\\n        \"--old_str\",\\n        type=str,\\n        default=None,\\n        help=\"Old string (for \\'str_replace\\')\",\\n    )\\n    parser.add_argument(\\n        \"--new_str\",\\n        type=str,\\n        default=None,\\n        help=\"New string (for \\'str_replace\\' or \\'insert\\')\",\\n    )\\n    parser.add_argument(\\n        \"--insert_line\",\\n        type=int,\\n        default=None,\\n        help=\"Line number to insert text at (for \\'insert\\')\",\\n    )\\n    parser.add_argument(\\n        \"--enable_linting\",\\n        type=bool,\\n        default=False,\\n        help=\"Enable linting checks for Python files before saving changes.\",\\n    )\\n    parser.add_argument(\\n        \"--concise\",\\n        type=str,\\n        default=\"False\",\\n        help=\"If True, attempts to produce a condensed view for Python files, eliding large function bodies.\",\\n    )\\n    parser.add_argument(\\n        \"--python_only\",\\n        type=bool,\\n        default=True,\\n        help=\"If True, attempts to limit view (for both dir and file level) to Python files only.\",\\n    )\\n\\n    args = parser.parse_args()\\n\\n    file_history = load_history()\\n    editor = StrReplaceEditor(file_history, enable_linting=args.enable_linting)\\n    if args.concise.lower() == \"true\":\\n        args.concise = True\\n    else:\\n        args.concise = False\\n\\n    try:\\n        result = editor.run(\\n            command=args.command,\\n            path_str=args.path,\\n            file_text=args.file_text,\\n            view_range=args.view_range,\\n            old_str=args.old_str,\\n            new_str=args.new_str,\\n            insert_line=args.insert_line,\\n            concise=args.concise,\\n        )\\n        safe_print(result.output)\\n        if result.error:\\n            safe_print(f\"ERROR: {result.error}\")\\n\\n    except EditorError as e:\\n        safe_print(f\"ERROR: {e}\")\\n    except Exception as e:\\n        safe_print(f\"ERROR: Unhandled exception: {e}\")\\n        import traceback\\n\\n        traceback.print_exc()\\n\\n    save_history(dict(editor.file_history))\\n\\n\\nif __name__ == \"__main__\":\\n    main()', name='file_editor', docstring='Description: Custom editing tool for viewing, creating and editing files\\n* State is persistent across command calls and discussions with the user\\n* If `path` is a file, `view` displays the result of applying `cat -n`. If `path` is a directory, `view` lists non-hidden files and directories up to 2 levels deep\\n* The `create` command cannot be used if the specified `path` already exists as a file\\n* If a `command` generates a long output, it will be truncated and marked with `<response clipped>`\\n* The `undo_edit` command will revert the last edit made to the file at `path`\\n\\nNotes for using the `str_replace` command:\\n* The `old_str` parameter should match EXACTLY one or more consecutive lines from the original file. Be mindful of whitespaces!\\n* If the `old_str` parameter is not unique in the file, the replacement will not be performed. Make sure to include enough context in `old_str` to make it unique\\n* The `new_str` parameter should contain the edited lines that should replace the `old_str`\\n\\nParameters:\\n  (1) command (string, required): The commands to run. Allowed options are: `view`, `create`, `str_replace`, `insert`, `undo_edit`.\\nAllowed values: [`view`, `create`, `str_replace`, `insert`, `undo_edit`]\\n  (2) path (string, required): Absolute path to file or directory, e.g. `/testbed/file.py` or `/testbed`.\\n  (3) file_text (string, optional): Required parameter of `create` command, with the content of the file to be created.\\n  (4) old_str (string, optional): Required parameter of `str_replace` command containing the string in `path` to replace.\\n  (5) new_str (string, optional): Optional parameter of `str_replace` command containing the new string (if not given, no string will be added). Required parameter of `insert` command containing the string to insert.\\n  (6) insert_line (integer, optional): Required parameter of `insert` command. The `new_str` will be inserted AFTER the line `insert_line` of `path`.\\n  (7) view_range (array, optional): Optional parameter of `view` command when `path` points to a file. If none is given, the full file is shown. If provided, the file will be shown in the indicated line number range, e.g. [11, 12] will show lines 11 and 12. Indexing at 1 to start. Setting `[start_line, -1]` shows all lines from `start_line` to the end of the file.\\n  (8) enable_linting (boolean, optional): Optional parameter to enable Python linting checks before saving changes. Default is `false`.\\n  (9) concise (boolean, optional): Optional parameter to enable a condensed view for Python files. Default is `false`. Super useful for understanding the structure of a Python file without getting bogged down in the details.', end_name=None, arguments=None, signature='file_editor')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from r2egym.agenthub.agent.commands import ParseCommandBash\n",
    "\n",
    "# cmd_parser = ParseCommandBash()\n",
    "# cmds = cmd_parser.parse_command_file(\"/scratch/git/R2E-Gym/src/r2egym/agenthub/tools/r2egym/file_editor.py\")\n",
    "# cmds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1ad79e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
